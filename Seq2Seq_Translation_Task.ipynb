{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"provenance":[]}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"XpqF-eDUv7_W","cell_type":"code","source":"!pip install sacrebleu","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XpqF-eDUv7_W","outputId":"c435c761-fb44-4939-881d-3547c6e077e4","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T13:45:59.941018Z","iopub.execute_input":"2024-11-24T13:45:59.941291Z","iopub.status.idle":"2024-11-24T13:46:10.112335Z","shell.execute_reply.started":"2024-11-24T13:45:59.941264Z","shell.execute_reply":"2024-11-24T13:46:10.111410Z"}},"outputs":[{"name":"stdout","text":"Collecting sacrebleu\n  Downloading sacrebleu-2.4.3-py3-none-any.whl.metadata (51 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting portalocker (from sacrebleu)\n  Downloading portalocker-3.0.0-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (2024.5.15)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (1.26.4)\nRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.4.6)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (5.3.0)\nDownloading sacrebleu-2.4.3-py3-none-any.whl (103 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.0/104.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading portalocker-3.0.0-py3-none-any.whl (19 kB)\nInstalling collected packages: portalocker, sacrebleu\nSuccessfully installed portalocker-3.0.0 sacrebleu-2.4.3\n","output_type":"stream"}],"execution_count":1},{"id":"3dfd9582-6ccf-4b5d-a84b-a33946670ee0","cell_type":"code","source":"!pip install evaluate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T13:46:10.113896Z","iopub.execute_input":"2024-11-24T13:46:10.114202Z","iopub.status.idle":"2024-11-24T13:46:18.736677Z","shell.execute_reply.started":"2024-11-24T13:46:10.114170Z","shell.execute_reply":"2024-11-24T13:46:18.735840Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"3dfd9582-6ccf-4b5d-a84b-a33946670ee0","outputId":"1142d8b8-6376-40ad-f5ef-9301b5c13c4e"},"outputs":[{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.0.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.2.2)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.25.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.15.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (16.1.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.5)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.8.30)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.3\n","output_type":"stream"}],"execution_count":2},{"id":"78dc75df","cell_type":"code","source":"import torch\nfrom transformers import MBartForConditionalGeneration, MBart50TokenizerFast, Seq2SeqTrainer, Seq2SeqTrainingArguments\nfrom datasets import load_dataset\nimport evaluate\nimport numpy as np\nfrom torch.utils.data import Dataset\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T13:47:53.018476Z","iopub.execute_input":"2024-11-24T13:47:53.018837Z","iopub.status.idle":"2024-11-24T13:48:13.555784Z","shell.execute_reply.started":"2024-11-24T13:47:53.018801Z","shell.execute_reply":"2024-11-24T13:48:13.554889Z"},"id":"78dc75df"},"outputs":[],"execution_count":3},{"id":"ad6c4dc7","cell_type":"code","source":"source_lang = \"ko\"\ntarget_lang = \"en\"\ndataset_name = f\"iwslt2017-{source_lang}-{target_lang}\"\ndataset = load_dataset(\"iwslt2017\", dataset_name)\nprint(dataset['train'][0])","metadata":{"scrolled":true,"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T13:48:17.286495Z","iopub.execute_input":"2024-11-24T13:48:17.287398Z","iopub.status.idle":"2024-11-24T13:48:28.247281Z","shell.execute_reply.started":"2024-11-24T13:48:17.287353Z","shell.execute_reply":"2024-11-24T13:48:28.246401Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"ad6c4dc7","outputId":"178c3a11-1664-4750-8f19-39066916522d"},"outputs":[{"output_type":"display_data","data":{"text/plain":"iwslt2017.py:   0%|          | 0.00/8.17k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7446b6e95e11495b9fecf3e1969d8d2b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/18.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fad51b00bb2f4efc8f664de421482f0e"}},"metadata":{}},{"output_type":"stream","name":"stdin","text":"The repository for iwslt2017 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/iwslt2017.\nYou can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n\nDo you wish to run the custom code? [y/N]  y\n"},{"output_type":"display_data","data":{"text/plain":"ko-en.zip:   0%|          | 0.00/19.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cdc66e183ac9495ca05c11ca71d042d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/230240 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e23cc4b438c94f0ba0ee13a93278170a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/8514 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec6b1dd6e322443286df5e7e74aca4c3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/879 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"166538e65c7e44c3828bc7b3d2217564"}},"metadata":{}},{"name":"stdout","text":"{'translation': {'en': 'Thank you so much, Chris.', 'ko': '감사합니다, 크리스. 이곳에 두 번이나'}}\n","output_type":"stream"}],"execution_count":4},{"id":"d719ca72","cell_type":"code","source":"from transformers import MBart50Tokenizer\n\ntokenizer = MBart50Tokenizer.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n\nprint(tokenizer.lang_code_to_id)\n\nsource_lang = 'en_XX'\ntarget_lang = 'ko_KR'\n\ntokenizer.src_lang = source_lang\ntokenizer.tgt_lang = target_lang","metadata":{"scrolled":true,"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T13:48:30.337892Z","iopub.execute_input":"2024-11-24T13:48:30.338370Z","iopub.status.idle":"2024-11-24T13:48:32.283486Z","shell.execute_reply.started":"2024-11-24T13:48:30.338332Z","shell.execute_reply":"2024-11-24T13:48:32.282533Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"d719ca72","outputId":"937cc605-f497-4df7-cd43-605d66bb1607"},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/529 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe41e5bb39ab4242a1b095f3548407ba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd0a50592c5045e488bba7214d9a8708"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/649 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6836891224e64daeb5ded0a3213ab773"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.43k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"216cb34d34cf4326a7167925309ec9ce"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"{'ar_AR': 250001, 'cs_CZ': 250002, 'de_DE': 250003, 'en_XX': 250004, 'es_XX': 250005, 'et_EE': 250006, 'fi_FI': 250007, 'fr_XX': 250008, 'gu_IN': 250009, 'hi_IN': 250010, 'it_IT': 250011, 'ja_XX': 250012, 'kk_KZ': 250013, 'ko_KR': 250014, 'lt_LT': 250015, 'lv_LV': 250016, 'my_MM': 250017, 'ne_NP': 250018, 'nl_XX': 250019, 'ro_RO': 250020, 'ru_RU': 250021, 'si_LK': 250022, 'tr_TR': 250023, 'vi_VN': 250024, 'zh_CN': 250025, 'af_ZA': 250026, 'az_AZ': 250027, 'bn_IN': 250028, 'fa_IR': 250029, 'he_IL': 250030, 'hr_HR': 250031, 'id_ID': 250032, 'ka_GE': 250033, 'km_KH': 250034, 'mk_MK': 250035, 'ml_IN': 250036, 'mn_MN': 250037, 'mr_IN': 250038, 'pl_PL': 250039, 'ps_AF': 250040, 'pt_XX': 250041, 'sv_SE': 250042, 'sw_KE': 250043, 'ta_IN': 250044, 'te_IN': 250045, 'th_TH': 250046, 'tl_XX': 250047, 'uk_UA': 250048, 'ur_PK': 250049, 'xh_ZA': 250050, 'gl_ES': 250051, 'sl_SI': 250052}\n","output_type":"stream"}],"execution_count":5},{"id":"7210d98f-d11e-40a9-a9c0-9e6f0c3cb103","cell_type":"code","source":"print(dataset['train'])\nprint(dataset['train'].column_names)\nprint(dataset['train'][0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T13:48:34.973798Z","iopub.execute_input":"2024-11-24T13:48:34.974634Z","iopub.status.idle":"2024-11-24T13:48:34.979488Z","shell.execute_reply.started":"2024-11-24T13:48:34.974595Z","shell.execute_reply":"2024-11-24T13:48:34.978621Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"7210d98f-d11e-40a9-a9c0-9e6f0c3cb103","outputId":"ca2e266c-2670-49e3-be57-860e77bcf41f"},"outputs":[{"name":"stdout","text":"Dataset({\n    features: ['translation'],\n    num_rows: 230240\n})\n['translation']\n{'translation': {'en': 'Thank you so much, Chris.', 'ko': '감사합니다, 크리스. 이곳에 두 번이나'}}\n","output_type":"stream"}],"execution_count":6},{"id":"837c95ae-7041-4623-b7b6-7cc50bf073cc","cell_type":"code","source":"def preprocess_function(examples):\n    inputs = [ex['en'] for ex in examples['translation']]\n    targets = [ex['ko'] for ex in examples['translation']]\n\n    model_inputs = tokenizer(inputs, max_length=128, truncation=True, padding='max_length')\n\n    labels = tokenizer(targets, max_length=128, truncation=True, padding='max_length')\n\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n\n    return model_inputs\n\ntokenized_datasets = dataset.map(preprocess_function, batched=True)\n\nprint(tokenized_datasets['train'].column_names)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T13:48:41.365665Z","iopub.execute_input":"2024-11-24T13:48:41.366383Z","iopub.status.idle":"2024-11-24T13:49:46.687610Z","shell.execute_reply.started":"2024-11-24T13:48:41.366346Z","shell.execute_reply":"2024-11-24T13:49:46.686778Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"837c95ae-7041-4623-b7b6-7cc50bf073cc","outputId":"49be8d82-c74a-49ce-92ce-92439b603c83"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/230240 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"508dce2ac08140529a205067f1374b8b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/8514 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86a980800cdb41b19c082053ab8379d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/879 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f97d4b8834449dabbc99bf91215ad99"}},"metadata":{}},{"name":"stdout","text":"['translation', 'input_ids', 'attention_mask', 'labels']\n","output_type":"stream"}],"execution_count":7},{"id":"e6bb0672-c291-4455-b3c3-e695df2ce754","cell_type":"code","source":"def preprocess_function(examples):\n    inputs = [ex['en'] for ex in examples['translation']]\n    targets = [ex['ko'] for ex in examples['translation']]\n    model_inputs = tokenizer(inputs, max_length=128, truncation=True)\n    labels = tokenizer(targets, max_length=128, truncation=True)\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs\n\ntokenized_datasets = dataset.map(\n    lambda batch: tokenizer(\n        [example['en'] for example in batch['translation']],\n        padding='max_length',\n        truncation=True,\n        max_length=128\n    ),\n    batched=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T13:50:02.272742Z","iopub.execute_input":"2024-11-24T13:50:02.273093Z","iopub.status.idle":"2024-11-24T13:50:41.848719Z","shell.execute_reply.started":"2024-11-24T13:50:02.273060Z","shell.execute_reply":"2024-11-24T13:50:41.848000Z"},"id":"e6bb0672-c291-4455-b3c3-e695df2ce754"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/230240 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae11d55f3e904b3b9b779f9df2e0ebba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/8514 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e1c871e51f54fc3ad0ca49c39f2ca21"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/879 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e08d9d958bf948b89c71607dacce741a"}},"metadata":{}}],"execution_count":8},{"id":"5589881f","cell_type":"code","source":"class TranslationDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, translations):\n        self.encodings = encodings\n        self.translations = translations\n\n    def __getitem__(self, idx):\n        item = {\n            \"input_ids\": torch.tensor(self.encodings[\"input_ids\"][idx]),\n            \"attention_mask\": torch.tensor(self.encodings[\"attention_mask\"][idx]),\n            \"labels\": torch.tensor(self.translations[\"input_ids\"][idx])\n        }\n        return item\n\n    def __len__(self):\n        return len(self.encodings[\"input_ids\"])\n\ntrain_encodings = tokenized_datasets[\"train\"]\ntrain_translations = tokenized_datasets[\"train\"]\n\ntrain_dataset = TranslationDataset(train_encodings, train_translations)\nval_dataset = TranslationDataset(tokenized_datasets[\"validation\"], tokenized_datasets[\"validation\"])\ntest_dataset = TranslationDataset(tokenized_datasets[\"test\"], tokenized_datasets[\"test\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T13:51:06.330505Z","iopub.execute_input":"2024-11-24T13:51:06.331088Z","iopub.status.idle":"2024-11-24T13:51:06.337281Z","shell.execute_reply.started":"2024-11-24T13:51:06.331052Z","shell.execute_reply":"2024-11-24T13:51:06.336384Z"},"id":"5589881f"},"outputs":[],"execution_count":9},{"id":"c0d4703c-7163-4cb5-b7ac-574635814cb0","cell_type":"code","source":"from transformers import MBartForConditionalGeneration, Seq2SeqTrainer, Seq2SeqTrainingArguments\n\nmodel_name = \"facebook/mbart-large-50\"\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel = MBartForConditionalGeneration.from_pretrained(model_name).to(device)\n\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=\"./results\",\n    eval_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    save_total_limit=3,\n    predict_with_generate=True,\n    fp16=True,\n    push_to_hub=False,\n)\n\nmetric = evaluate.load(\"sacrebleu\")\n\ndef compute_metrics(eval_preds):\n    preds, labels = eval_preds\n    preds = np.where(preds != -100, preds, tokenizer.pad_token_id)\n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    decoded_labels = [[label] for label in decoded_labels]\n    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n    return {\"bleu\": result[\"score\"]}\n\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n)\n\nprint(tokenized_datasets)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T13:59:27.169839Z","iopub.execute_input":"2024-11-24T13:59:27.170302Z","iopub.status.idle":"2024-11-24T13:59:40.631163Z","shell.execute_reply.started":"2024-11-24T13:59:27.170269Z","shell.execute_reply":"2024-11-24T13:59:40.630253Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/8.15k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"902237bf96d7458f992a140d94e6b921"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n","output_type":"stream"},{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['translation', 'input_ids', 'attention_mask'],\n        num_rows: 230240\n    })\n    test: Dataset({\n        features: ['translation', 'input_ids', 'attention_mask'],\n        num_rows: 8514\n    })\n    validation: Dataset({\n        features: ['translation', 'input_ids', 'attention_mask'],\n        num_rows: 879\n    })\n})\n","output_type":"stream"}],"execution_count":12},{"id":"fac6e34a-0a3a-4f6b-80a6-b33a7baf2d44","cell_type":"code","source":"print(tokenized_datasets.column_names)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T14:00:27.383397Z","iopub.execute_input":"2024-11-24T14:00:27.383735Z","iopub.status.idle":"2024-11-24T14:00:27.388359Z","shell.execute_reply.started":"2024-11-24T14:00:27.383706Z","shell.execute_reply":"2024-11-24T14:00:27.387528Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"fac6e34a-0a3a-4f6b-80a6-b33a7baf2d44","outputId":"1707d8f7-53f4-49be-c9b0-6093e268e745"},"outputs":[{"name":"stdout","text":"{'train': ['translation', 'input_ids', 'attention_mask'], 'test': ['translation', 'input_ids', 'attention_mask'], 'validation': ['translation', 'input_ids', 'attention_mask']}\n","output_type":"stream"}],"execution_count":13},{"id":"-pDegsRHaqIw","cell_type":"code","source":"def compute_metrics(eval_preds):\n    preds, labels = eval_preds\n\n    preds = torch.tensor(preds).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    labels = torch.tensor(labels).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    preds = torch.where(preds != -100, preds, tokenizer.pad_token_id)\n    labels = torch.where(labels != -100, labels, tokenizer.pad_token_id)\n\n    decoded_preds = tokenizer.batch_decode(preds.tolist(), skip_special_tokens=True)\n    decoded_labels = tokenizer.batch_decode(labels.tolist(), skip_special_tokens=True)\n\n    decoded_labels = [[label] for label in decoded_labels]\n\n    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n\n    return {\"test_bleu\": result[\"score\"]}\n\ntest_results = trainer.evaluate(eval_dataset=test_dataset, metric_key_prefix=\"test\")\nprint(\"Test BLEU score:\", test_results[\"test_bleu\"])","metadata":{"id":"-pDegsRHaqIw","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T14:00:32.239737Z","iopub.execute_input":"2024-11-24T14:00:32.240394Z","iopub.status.idle":"2024-11-24T17:28:10.902865Z","shell.execute_reply.started":"2024-11-24T14:00:32.240349Z","shell.execute_reply":"2024-11-24T17:28:10.902024Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='267' max='267' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [267/267 3:23:33]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01111363797778419, max=1.0)…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42e86cc08f0b405aa147e0ae8f7f53d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241124_172807-e8uu8uk2</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/z20030306-hanyang-university/huggingface/runs/e8uu8uk2' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/z20030306-hanyang-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/z20030306-hanyang-university/huggingface' target=\"_blank\">https://wandb.ai/z20030306-hanyang-university/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/z20030306-hanyang-university/huggingface/runs/e8uu8uk2' target=\"_blank\">https://wandb.ai/z20030306-hanyang-university/huggingface/runs/e8uu8uk2</a>"},"metadata":{}},{"name":"stdout","text":"Test BLEU score: 88.89412604743973\n","output_type":"stream"}],"execution_count":14},{"id":"d9468a06-ce5f-4f60-93ed-109efaae534b","cell_type":"code","source":"import torch\ntorch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T09:00:32.596403Z","iopub.status.idle":"2024-11-23T09:00:32.596720Z","shell.execute_reply.started":"2024-11-23T09:00:32.596573Z","shell.execute_reply":"2024-11-23T09:00:32.596593Z"},"id":"d9468a06-ce5f-4f60-93ed-109efaae534b"},"outputs":[],"execution_count":null},{"id":"88808f6c-1638-4e72-92d5-e32da98210dc","cell_type":"code","source":"","metadata":{"trusted":true,"id":"88808f6c-1638-4e72-92d5-e32da98210dc"},"outputs":[],"execution_count":null},{"id":"7cafeac4-30ca-4e8f-95d4-8283654c48b3","cell_type":"code","source":"","metadata":{"trusted":true,"id":"7cafeac4-30ca-4e8f-95d4-8283654c48b3"},"outputs":[],"execution_count":null}]}